{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I've been running this on my laptop, which turns out to be faster than (free) Google Colab,\n",
    "# and this shows whether I have it set up right to use the GPU:\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to toggle adjustments I've made to the cleanup\n",
    "DROP_STATUS = True        # Maybe slightly harmful\n",
    "DROP_INCOME_AMT = True    # Maybe slightly harmful\n",
    "DROP_ASK_AMT = True       # Unclear\n",
    "DROP_APP_TYPE = False      # Very harmful\n",
    "DROP_CLASS = False         # Harmful\n",
    "DROP_AFFILIATION = False   # Harmful\n",
    "DROP_USE_CASE = False      # Harmful\n",
    "DROP_ORGANIZATION = False  # Harmful\n",
    "DROP_SPECIAL = True        # Maybe helpful\n",
    "\n",
    "ADD_INCOME_MID = False           # Not helpful\n",
    "ADD_INCOME_ASK_RATIO = False     # Not helpful\n",
    "\n",
    "APPLICATION_CUTOFF = 100     # Originally 300\n",
    "CLASSIFICATION_CUTOFF = 50   # Originally 1000\n",
    "\n",
    "# Whether to run the tuner or the hard-coded network build code\n",
    "TUNE_NETWORK = False\n",
    "BUILD_NETWORK = not TUNE_NETWORK\n",
    "\n",
    "# Random seed for train_test_split()\n",
    "SPLIT_SEED = 8675309       # Originally 8675309\n",
    "SPLIT_TEST_SIZE = 0.25     # Originally 0.25 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "del application_df[\"EIN\"]\n",
    "del application_df[\"NAME\"]\n",
    "\n",
    "# Also drop STATUS since there only 5 non-active rows\n",
    "if DROP_STATUS:\n",
    "    del application_df[\"STATUS\"]\n",
    "\n",
    "if DROP_APP_TYPE:\n",
    "    del application_df[\"APPLICATION_TYPE\"]\n",
    "if DROP_CLASS:\n",
    "    del application_df[\"CLASSIFICATION\"]\n",
    "if DROP_AFFILIATION:\n",
    "    del application_df[\"AFFILIATION\"]\n",
    "if DROP_USE_CASE:\n",
    "    del application_df[\"USE_CASE\"]\n",
    "if DROP_ORGANIZATION:\n",
    "    del application_df[\"ORGANIZATION\"]\n",
    "if DROP_SPECIAL:\n",
    "    del application_df[\"SPECIAL_CONSIDERATIONS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE      17\n",
       "AFFILIATION            6\n",
       "CLASSIFICATION        71\n",
       "USE_CASE               5\n",
       "ORGANIZATION           4\n",
       "INCOME_AMT             9\n",
       "ASK_AMT             8747\n",
       "IS_SUCCESSFUL          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLICATION_TYPE\n",
      "T3     27037\n",
      "T4      1542\n",
      "T6      1216\n",
      "T5      1173\n",
      "T19     1065\n",
      "T8       737\n",
      "T7       725\n",
      "T10      528\n",
      "T9       156\n",
      "T13       66\n",
      "T12       27\n",
      "T2        16\n",
      "T25        3\n",
      "T14        3\n",
      "T29        2\n",
      "T15        2\n",
      "T17        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
    "if not DROP_APP_TYPE:\n",
    "    v_counts = application_df[\"APPLICATION_TYPE\"].value_counts()    \n",
    "    print(v_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLICATION_TYPE\n",
      "T3       27037\n",
      "T4        1542\n",
      "T6        1216\n",
      "T5        1173\n",
      "T19       1065\n",
      "T8         737\n",
      "T7         725\n",
      "T10        528\n",
      "T9         156\n",
      "Other      120\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "if not DROP_APP_TYPE:\n",
    "    application_types_to_replace = v_counts[v_counts < APPLICATION_CUTOFF].index.values\n",
    "    \n",
    "    # Replace in dataframe\n",
    "    for app in application_types_to_replace:\n",
    "        application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "    \n",
    "    # Check to make sure replacement was successful\n",
    "    print(application_df['APPLICATION_TYPE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION\n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "         ...  \n",
      "C4120        1\n",
      "C8210        1\n",
      "C2561        1\n",
      "C4500        1\n",
      "C2150        1\n",
      "Name: count, Length: 71, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
    "if not DROP_CLASS:    \n",
    "    v_counts = application_df[\"CLASSIFICATION\"].value_counts()\n",
    "    # Disabled because I'm tired of scrolling past it:\n",
    "    print(v_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION\n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "C7000      777\n",
      "C1700      287\n",
      "C4000      194\n",
      "C5000      116\n",
      "C1270      114\n",
      "C2700      104\n",
      "C2800       95\n",
      "C7100       75\n",
      "C1300       58\n",
      "C1280       50\n",
      "C1230       36\n",
      "C1400       34\n",
      "C7200       32\n",
      "C2300       32\n",
      "C1240       30\n",
      "C8000       20\n",
      "C7120       18\n",
      "C1500       16\n",
      "C1800       15\n",
      "C6000       15\n",
      "C1250       14\n",
      "C8200       11\n",
      "C1238       10\n",
      "C1278       10\n",
      "C1235        9\n",
      "C1237        9\n",
      "C7210        7\n",
      "C2400        6\n",
      "C1720        6\n",
      "C4100        6\n",
      "C1257        5\n",
      "C1600        5\n",
      "C1260        3\n",
      "C2710        3\n",
      "C0           3\n",
      "C3200        2\n",
      "C1234        2\n",
      "C1246        2\n",
      "C1267        2\n",
      "C1256        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "if not DROP_CLASS:\n",
    "    print(v_counts[v_counts > 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION\n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "C7000      777\n",
      "Other      391\n",
      "C1700      287\n",
      "C4000      194\n",
      "C5000      116\n",
      "C1270      114\n",
      "C2700      104\n",
      "C2800       95\n",
      "C7100       75\n",
      "C1300       58\n",
      "C1280       50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "if not DROP_CLASS:\n",
    "    classifications_to_replace = v_counts[v_counts < CLASSIFICATION_CUTOFF].index.values\n",
    "    \n",
    "    # Replace in dataframe\n",
    "    for cls in classifications_to_replace:\n",
    "        application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "    # Check to make sure replacement was successful\n",
    "    print(application_df['CLASSIFICATION'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The INCOME_AMT column is categorical but could be numerical, which might be helpful.\n",
    "if ADD_INCOME_MID:\n",
    "    application_df[\"INCOME_MID\"] = application_df[\"INCOME_AMT\"].map({\n",
    "        \"0\": 0,\n",
    "        \"25000-99999\": 62499.5,\n",
    "        \"100000-499999\": 299999.5,\n",
    "        \"1M-5M\": 3000000,\n",
    "        \"1-9999\": 5000,\n",
    "        \"10000-24999\": 17499.5,\n",
    "        \"10M-50M\": 30000000,\n",
    "        \"5M-10M\": 7500000,\n",
    "        \"50M+\": 50000000})\n",
    "    print(application_df[\"INCOME_MID\"].value_counts())\n",
    "\n",
    "if DROP_INCOME_AMT:\n",
    "    del application_df[\"INCOME_AMT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplement the ask and income columns with a ratio\n",
    "if ADD_INCOME_ASK_RATIO:\n",
    "    application_df[\"INCOME_ASK_RATIO\"] = application_df[\"INCOME_MID\"] / application_df[\"ASK_AMT\"]\n",
    "\n",
    "# Surprisingly, the overwhelming about of loans are asking for the same amount of money, $5000,\n",
    "# which could badly skew the model. So drop that column.\n",
    "if DROP_ASK_AMT:\n",
    "    del application_df[\"ASK_AMT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the SPECIAL_CONSIDERATIONS column into something more easily usable\n",
    "if not DROP_SPECIAL:\n",
    "    application_df[\"SPECIAL_CONSIDERATIONS\"] = application_df[\"SPECIAL_CONSIDERATIONS\"].map({\"Y\":1, \"N\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0              1                   False                  True   \n",
       "1              1                   False                 False   \n",
       "2              0                   False                 False   \n",
       "3              1                   False                 False   \n",
       "4              1                   False                 False   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                 False                False                False   \n",
       "1                 False                 True                False   \n",
       "2                 False                False                False   \n",
       "3                 False                 True                False   \n",
       "4                 False                 True                False   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  \\\n",
       "0                False                False                False   \n",
       "1                False                False                False   \n",
       "2                 True                False                False   \n",
       "3                False                False                False   \n",
       "4                False                False                False   \n",
       "\n",
       "   APPLICATION_TYPE_T8  ...  AFFILIATION_Regional  USE_CASE_CommunityServ  \\\n",
       "0                False  ...                 False                   False   \n",
       "1                False  ...                 False                   False   \n",
       "2                False  ...                 False                   False   \n",
       "3                False  ...                 False                   False   \n",
       "4                False  ...                 False                   False   \n",
       "\n",
       "   USE_CASE_Heathcare  USE_CASE_Other  USE_CASE_Preservation  \\\n",
       "0               False           False                  False   \n",
       "1               False           False                   True   \n",
       "2               False           False                  False   \n",
       "3               False           False                   True   \n",
       "4                True           False                  False   \n",
       "\n",
       "   USE_CASE_ProductDev  ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                 True                      True                      False   \n",
       "1                False                     False                       True   \n",
       "2                 True                      True                      False   \n",
       "3                False                     False                      False   \n",
       "4                False                     False                      False   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  \n",
       "0                     False               False  \n",
       "1                     False               False  \n",
       "2                     False               False  \n",
       "3                     False                True  \n",
       "4                     False                True  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "cat_columns = []\n",
    "\n",
    "if not DROP_INCOME_AMT:\n",
    "    cat_columns.append(\"INCOME_AMT\")\n",
    "if not DROP_APP_TYPE:\n",
    "    cat_columns.append(\"APPLICATION_TYPE\")\n",
    "if not DROP_CLASS:\n",
    "    cat_columns.append(\"CLASSIFICATION\")\n",
    "if not DROP_AFFILIATION:\n",
    "    cat_columns.append(\"AFFILIATION\")\n",
    "if not DROP_USE_CASE:\n",
    "    cat_columns.append(\"USE_CASE\")\n",
    "if not DROP_ORGANIZATION:\n",
    "    cat_columns.append(\"ORGANIZATION\")\n",
    "\n",
    "dummied_df = pd.get_dummies(application_df, columns=cat_columns)\n",
    "dummied_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34299, 41) (34299,) (25724, 41) (8575, 41) (25724,) (8575,)\n",
      "X_train: APPLICATION_TYPE_Other\n",
      "False    25636\n",
      "True        88\n",
      "Name: count, dtype: int64\n",
      "X_test : APPLICATION_TYPE_Other\n",
      "False    8543\n",
      "True       32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: APPLICATION_TYPE_T10\n",
      "False    25327\n",
      "True       397\n",
      "Name: count, dtype: int64\n",
      "X_test : APPLICATION_TYPE_T10\n",
      "False    8444\n",
      "True      131\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: APPLICATION_TYPE_T19\n",
      "False    24907\n",
      "True       817\n",
      "Name: count, dtype: int64\n",
      "X_test : APPLICATION_TYPE_T19\n",
      "False    8327\n",
      "True      248\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: APPLICATION_TYPE_T3\n",
      "True     20214\n",
      "False     5510\n",
      "Name: count, dtype: int64\n",
      "X_test : APPLICATION_TYPE_T3\n",
      "True     6823\n",
      "False    1752\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: APPLICATION_TYPE_T4\n",
      "False    24540\n",
      "True      1184\n",
      "Name: count, dtype: int64\n",
      "X_test : APPLICATION_TYPE_T4\n",
      "False    8217\n",
      "True      358\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: APPLICATION_TYPE_T5\n",
      "False    24832\n",
      "True       892\n",
      "Name: count, dtype: int64\n",
      "X_test : APPLICATION_TYPE_T5\n",
      "False    8294\n",
      "True      281\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: APPLICATION_TYPE_T6\n",
      "False    24808\n",
      "True       916\n",
      "Name: count, dtype: int64\n",
      "X_test : APPLICATION_TYPE_T6\n",
      "False    8275\n",
      "True      300\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: APPLICATION_TYPE_T7\n",
      "False    25181\n",
      "True       543\n",
      "Name: count, dtype: int64\n",
      "X_test : APPLICATION_TYPE_T7\n",
      "False    8393\n",
      "True      182\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: APPLICATION_TYPE_T8\n",
      "False    25166\n",
      "True       558\n",
      "Name: count, dtype: int64\n",
      "X_test : APPLICATION_TYPE_T8\n",
      "False    8396\n",
      "True      179\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: APPLICATION_TYPE_T9\n",
      "False    25609\n",
      "True       115\n",
      "Name: count, dtype: int64\n",
      "X_test : APPLICATION_TYPE_T9\n",
      "False    8534\n",
      "True       41\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C1000\n",
      "True     12949\n",
      "False    12775\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C1000\n",
      "True     4377\n",
      "False    4198\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C1200\n",
      "False    22077\n",
      "True      3647\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C1200\n",
      "False    7385\n",
      "True     1190\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C1270\n",
      "False    25646\n",
      "True        78\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C1270\n",
      "False    8539\n",
      "True       36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C1280\n",
      "False    25684\n",
      "True        40\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C1280\n",
      "False    8565\n",
      "True       10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C1300\n",
      "False    25681\n",
      "True        43\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C1300\n",
      "False    8560\n",
      "True       15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C1700\n",
      "False    25503\n",
      "True       221\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C1700\n",
      "False    8509\n",
      "True       66\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C2000\n",
      "False    21186\n",
      "True      4538\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C2000\n",
      "False    7039\n",
      "True     1536\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C2100\n",
      "False    24294\n",
      "True      1430\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C2100\n",
      "False    8122\n",
      "True      453\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C2700\n",
      "False    25639\n",
      "True        85\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C2700\n",
      "False    8556\n",
      "True       19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C2800\n",
      "False    25657\n",
      "True        67\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C2800\n",
      "False    8547\n",
      "True       28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C3000\n",
      "False    24250\n",
      "True      1474\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C3000\n",
      "False    8131\n",
      "True      444\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C4000\n",
      "False    25582\n",
      "True       142\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C4000\n",
      "False    8523\n",
      "True       52\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C5000\n",
      "False    25641\n",
      "True        83\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C5000\n",
      "False    8542\n",
      "True       33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C7000\n",
      "False    25149\n",
      "True       575\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C7000\n",
      "False    8373\n",
      "True      202\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_C7100\n",
      "False    25671\n",
      "True        53\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_C7100\n",
      "False    8553\n",
      "True       22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: CLASSIFICATION_Other\n",
      "False    25425\n",
      "True       299\n",
      "Name: count, dtype: int64\n",
      "X_test : CLASSIFICATION_Other\n",
      "False    8483\n",
      "True       92\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: AFFILIATION_CompanySponsored\n",
      "False    13892\n",
      "True     11832\n",
      "Name: count, dtype: int64\n",
      "X_test : AFFILIATION_CompanySponsored\n",
      "False    4702\n",
      "True     3873\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: AFFILIATION_Family/Parent\n",
      "False    25677\n",
      "True        47\n",
      "Name: count, dtype: int64\n",
      "X_test : AFFILIATION_Family/Parent\n",
      "False    8558\n",
      "True       17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: AFFILIATION_Independent\n",
      "True     13807\n",
      "False    11917\n",
      "Name: count, dtype: int64\n",
      "X_test : AFFILIATION_Independent\n",
      "True     4673\n",
      "False    3902\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: AFFILIATION_National\n",
      "False    25695\n",
      "True        29\n",
      "Name: count, dtype: int64\n",
      "X_test : AFFILIATION_National\n",
      "False    8571\n",
      "True        4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: AFFILIATION_Other\n",
      "False    25724\n",
      "Name: count, dtype: int64\n",
      "X_test : AFFILIATION_Other\n",
      "False    8571\n",
      "True        4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: AFFILIATION_Regional\n",
      "False    25715\n",
      "True         9\n",
      "Name: count, dtype: int64\n",
      "X_test : AFFILIATION_Regional\n",
      "False    8571\n",
      "True        4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: USE_CASE_CommunityServ\n",
      "False    25432\n",
      "True       292\n",
      "Name: count, dtype: int64\n",
      "X_test : USE_CASE_CommunityServ\n",
      "False    8483\n",
      "True       92\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: USE_CASE_Heathcare\n",
      "False    25601\n",
      "True       123\n",
      "Name: count, dtype: int64\n",
      "X_test : USE_CASE_Heathcare\n",
      "False    8552\n",
      "True       23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: USE_CASE_Other\n",
      "False    25722\n",
      "True         2\n",
      "Name: count, dtype: int64\n",
      "X_test : USE_CASE_Other\n",
      "False    8574\n",
      "True        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: USE_CASE_Preservation\n",
      "True     21002\n",
      "False     4722\n",
      "Name: count, dtype: int64\n",
      "X_test : USE_CASE_Preservation\n",
      "True     7093\n",
      "False    1482\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: USE_CASE_ProductDev\n",
      "False    21419\n",
      "True      4305\n",
      "Name: count, dtype: int64\n",
      "X_test : USE_CASE_ProductDev\n",
      "False    7209\n",
      "True     1366\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: ORGANIZATION_Association\n",
      "False    17937\n",
      "True      7787\n",
      "Name: count, dtype: int64\n",
      "X_test : ORGANIZATION_Association\n",
      "False    6107\n",
      "True     2468\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: ORGANIZATION_Co-operative\n",
      "False    25356\n",
      "True       368\n",
      "Name: count, dtype: int64\n",
      "X_test : ORGANIZATION_Co-operative\n",
      "False    8457\n",
      "True      118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: ORGANIZATION_Corporation\n",
      "False    25694\n",
      "True        30\n",
      "Name: count, dtype: int64\n",
      "X_test : ORGANIZATION_Corporation\n",
      "False    8562\n",
      "True       13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X_train: ORGANIZATION_Trust\n",
      "True     17539\n",
      "False     8185\n",
      "Name: count, dtype: int64\n",
      "X_test : ORGANIZATION_Trust\n",
      "True     5976\n",
      "False    2599\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = dummied_df.loc[:, dummied_df.columns != \"IS_SUCCESSFUL\"]\n",
    "y = dummied_df[\"IS_SUCCESSFUL\"]\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=SPLIT_TEST_SIZE, random_state=SPLIT_SEED)\n",
    "print(X.shape, y.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Extra info to get a sense for how well it split:\n",
    "for column in X.columns:\n",
    "    print(f\"X_train: {X_train[column].value_counts()}\")\n",
    "    print(f\"X_test : {X_test[column].value_counts()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25724, 41), (8575, 41))"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperband Search for Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 Complete [00h 00m 25s]\n",
      "val_accuracy: 0.7323032021522522\n",
      "\n",
      "Best val_accuracy So Far: 0.7323032021522522\n",
      "Total elapsed time: 00h 04m 31s\n",
      "\n",
      "Search: Running Trial #14\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "9                 |3                 |layer_count\n",
      "tanh              |tanh              |activation_0000\n",
      "82                |41                |units______0000\n",
      "silu              |relu6             |activation_0001\n",
      "41                |20                |units______0001\n",
      "relu6             |mish              |activation_0002\n",
      "20                |82                |units______0002\n",
      "mish              |gelu              |activation_0003\n",
      "13                |82                |units______0003\n",
      "gelu              |tanh              |activation_0004\n",
      "13                |82                |units______0004\n",
      "gelu              |mish              |activation_0005\n",
      "13                |20                |units______0005\n",
      "gelu              |relu6             |activation_0006\n",
      "41                |20                |units______0006\n",
      "tanh              |mish              |activation_0007\n",
      "20                |20                |units______0007\n",
      "relu6             |gelu              |activation_0008\n",
      "82                |20                |units______0008\n",
      "5                 |5                 |tuner/epochs\n",
      "2                 |2                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "1                 |1                 |tuner/round\n",
      "0010              |0006              |tuner/trial_id\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roy/anaconda3/envs/dev_1102/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.7223 - loss: 0.5605 - val_accuracy: 0.7305 - val_loss: 0.5559\n",
      "Epoch 4/5\n",
      "\u001b[1m734/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7184 - loss: 0.5666"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:58\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m--> 855\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function_type_utils\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    856\u001b[0m     args,\n\u001b[1;32m    857\u001b[0m     kwds,\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_type,\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_values,\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_pure,\n\u001b[1;32m    861\u001b[0m )\n\u001b[1;32m    862\u001b[0m args, kwds \u001b[38;5;241m=\u001b[39m bound_args\u001b[38;5;241m.\u001b[39margs, bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:422\u001b[0m, in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values, is_pure)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_pure:\n\u001b[1;32m    421\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m _convert_variables_to_tensors(args, kwargs)\n\u001b[0;32m--> 422\u001b[0m bound_arguments \u001b[38;5;241m=\u001b[39m bind_function_inputs(\n\u001b[1;32m    423\u001b[0m     args, kwargs, function_type, default_values\n\u001b[1;32m    424\u001b[0m )\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bound_arguments\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:442\u001b[0m, in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    435\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName collision after sanitization. Please rename \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.function input parameters. Original: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Sanitized: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(sanitized_kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m   )\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mbind_with_defaults(\n\u001b[1;32m    443\u001b[0m       args, sanitized_kwargs, default_values\n\u001b[1;32m    444\u001b[0m   )\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinding inputs to tf.function failed due to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msanitized_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for signature:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m   ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:264\u001b[0m, in \u001b[0;36mFunctionType.bind_with_defaults\u001b[0;34m(self, args, kwargs, default_values)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_defaults\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs, default_values):\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns BoundArguments with default values filled in.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    265\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[1;32m    267\u001b[0m   with_default_args \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mOrderedDict()\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/inspect.py:3273\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3271\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3272\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bind(args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/inspect.py:3266\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3262\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3263\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   3264\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[0;32m-> 3266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev_1102/lib/python3.12/inspect.py:2884\u001b[0m, in \u001b[0;36mBoundArguments.__init__\u001b[0;34m(self, signature, arguments)\u001b[0m\n\u001b[1;32m   2866\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Result of `Signature.bind` call.  Holds the mapping of arguments\u001b[39;00m\n\u001b[1;32m   2867\u001b[0m \u001b[38;5;124;03mto the function's parameters.\u001b[39;00m\n\u001b[1;32m   2868\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2879\u001b[0m \u001b[38;5;124;03m    Dict of keyword arguments values.\u001b[39;00m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2882\u001b[0m \u001b[38;5;18m__slots__\u001b[39m \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_signature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__weakref__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2884\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, signature, arguments):\n\u001b[1;32m   2885\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marguments \u001b[38;5;241m=\u001b[39m arguments\n\u001b[1;32m   2886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature \u001b[38;5;241m=\u001b[39m signature\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "MAX_EPOCHS_PER_MODEL = 15 # Meant to get a decent idea of parameter, not create a final model\n",
    "HYPERBAND_ITERATIONS = 1  # \"Number of times to iterate over the full Hyperband algorithm\"\n",
    "EXECUTIONS_PER_TRIAL = 2  # Training from scratch\n",
    "SEARCH_FIT_EPOCHS = 15    # Epochs for each attempt to do a fit, I think. Not sure how this relates to MAX_EPOCHS_PER_MODEL.\n",
    "OVERWRITE = True          # I'm hoping to be able to interrupt a run and resume it later\n",
    "\n",
    "#ACTIVATIONS = [\"tanh\", \"relu\", \"elu\", \"selu\", \"exponential\", \"gelu\", \"mish\", \"relu6\", \"silu\"]\n",
    "#LAYER_COUNTS = [6, 12]\n",
    "#UNITS_PER_LAYER_COUNTS = [30, 60]\n",
    "\n",
    "#ACTIVATIONS = [\"tanh\", \"relu\", \"elu\", \"selu\", \"exponential\", \"gelu\", \"mish\", \"relu6\", \"silu\"] -> Favorite: gelu\n",
    "#ACTIVATIONS = [\"tanh\", \"relu\", \"elu\", \"selu\"]                                                 -> Favorite: tanh (surprise!)\n",
    "#ACTIVATIONS = [\"exponential\", \"mish\", \"relu6\", \"silu\"]                                        -> Favorites: relu6 or mish, silu\n",
    "\n",
    "ACTIVATIONS = [\"tanh\", \"gelu\", \"mish\", \"relu6\", \"silu\"]\n",
    "LAYER_COUNTS = [1, 3, 9]\n",
    "UNITS_PER_LAYER_COUNTS = [X.shape[1] * 2, X.shape[1], X.shape[1] // 2, X.shape[1] // 3]\n",
    "\n",
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    in_shape = (X.shape[1],)\n",
    "    nn.add(tf.keras.Input(shape=in_shape))    \n",
    "\n",
    "    # Hidden layers\n",
    "    layer_count = hp.Choice(f'layer_count', LAYER_COUNTS)\n",
    "    for l in range(layer_count):\n",
    "        # Select activation and number of units for this layer\n",
    "        activation = hp.Choice(f'activation_{l:04}', ACTIVATIONS)\n",
    "        units =      hp.Choice(f'units______{l:04}', UNITS_PER_LAYER_COUNTS)\n",
    "\n",
    "        # Add this layer\n",
    "        nn.add(tf.keras.layers.Dense(units=units, activation=activation))\n",
    "        \n",
    "\n",
    "\n",
    "    # Output layer    \n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn\n",
    "\n",
    "\n",
    "# Run the kerastuner search for best hyperparameters\n",
    "if TUNE_NETWORK:\n",
    "    tuner = kt.Hyperband(\n",
    "        create_model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_epochs=MAX_EPOCHS_PER_MODEL,\n",
    "        hyperband_iterations=HYPERBAND_ITERATIONS,\n",
    "        executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
    "        overwrite=OVERWRITE)\n",
    "    tuner.search(X_train_scaled,y_train,epochs=SEARCH_FIT_EPOCHS,validation_data=(X_test_scaled,y_test))\n",
    "    \n",
    "    best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "    print(f\"Best Hyper Values: {best_hyper.values}\")\n",
    "    \n",
    "    best_model = tuner.get_best_models(1)[0]\n",
    "    model_loss, model_accuracy = best_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Best Model: Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "ITERATE = True\n",
    "\n",
    "if BUILD_NETWORK:\n",
    "    in_shape = (X.shape[1],)\n",
    "    nn = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    nn.add(tf.keras.Input(shape=in_shape))\n",
    "\n",
    "    if ITERATE:\n",
    "        #As = [\"gelu\", \"mish\", \"relu6\", \"tanh\", \"sigmoid\", \"exponential\"]\n",
    "        As = [\"tanh\", \"relu\", \"elu\", \"selu\", \"exponential\", \"gelu\", \"mish\", \"relu6\", \"silu\"]\n",
    "        us = [X.shape[1] * 2, X.shape[1], X.shape[1] // 2, X.shape[1] // 3]\n",
    "        \n",
    "        for u in us:\n",
    "            for a in As:\n",
    "                nn.add(tf.keras.layers.Dense(units=u, activation=a))\n",
    "    else:\n",
    "        # This came out of a hypertuner run\n",
    "        if False:\n",
    "            nn.add(tf.keras.layers.Dense(units=30, activation=\"gelu\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=60, activation=\"mish\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=60, activation=\"mish\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=30, activation=\"relu6\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=30, activation=\"mish\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=30, activation=\"mish\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=30, activation=\"silu\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=30, activation=\"gelu\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=30, activation=\"relu6\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=60, activation=\"tanh\"))\n",
    "        else:\n",
    "            u = 32\n",
    "            nn.add(tf.keras.layers.Dense(units=u, activation=\"sigmoid\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=u, activation=\"gelu\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=u, activation=\"exponential\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=u, activation=\"mish\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=u, activation=\"sigmoid\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=u, activation=\"relu6\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=u, activation=\"sigmoid\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=u, activation=\"silu\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=u, activation=\"sigmoid\"))\n",
    "            nn.add(tf.keras.layers.Dense(units=u, activation=\"tanh\"))\n",
    "    \n",
    "    # Output layer\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # Check the structure of the model\n",
    "    nn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training checkpoint to save after each epoch, if it is a new best model:\n",
    "checkpoint_filepath = './best.keras'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 μs, sys: 1e+03 ns, total: 5 μs\n",
      "Wall time: 8.58 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 15\n",
    "if BUILD_NETWORK:    \n",
    "    # Compile the model\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])    \n",
    "    \n",
    "    # Train the model\n",
    "    nn.fit(X_train_scaled, y_train, epochs=EPOCHS, callbacks=[model_checkpoint_callback])\n",
    "    \n",
    "    model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Final Model, Test Set results: Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "    \n",
    "    model_loss, model_accuracy = tf.keras.models.load_model(checkpoint_filepath).evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Best  Model, Test Set results: Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity_Optimization.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
